## Table of Content
1. [Introduction](#Introduction)
2. [Framework](#Framework)
3. [Hand Segmentation](#Hand-Segmentation)
4. [CNN Model](#CNN-Model)
5. [Results](#results)
6. [Conclusion and future work](#conclusion-and-future-work)
7. [References](#reference)

### Introduction
Gesture recognition is an active research field that tries to integrate the gestural channel in Human-Computer interaction. It has a variety of applications like virtual environment control, sign language translation, robot remote control, musical creation[1], etc. Several applications have been built around human gestures, wherein the detected gesture triggers a command or serves as an input to the system. It has proven to be useful and enhance user experience in many scenarios.
<br>
A configurable framework for gesture recognition can let application developers easily incorporate gesture controls onto their system by mapping gestures to their corresponding actions depending upon their implementation logic. Applications can support sophisticated user interfaces with significantly less effort. Since the existing approaches require external equipment like gloves or fixed background to detect the hand, it makes the task of integrating with other applications difficult. So, a framework that detects gestures using only the raw input feed from the camera could be a promising tool for application development.
